{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd7f54e",
   "metadata": {},
   "source": [
    "code being adapted from: https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1272b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from itertools import cycle, islice\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import EmpiricalCovariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ae8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.zeros(num_feat)\n",
    "\n",
    "# cov = [[1, 0], [0, 1]]\n",
    "\n",
    "# x = np.random.multivariate_normal(mean, cov, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run blob_distCurve_metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf9a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ellips_homosk_clusters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a3e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heteroskedastic_anisotropic_blobs_nd(\n",
    "    n_samples=1000,\n",
    "    n_features=3,\n",
    "    cluster_std=1.0,\n",
    "    transforms=None,\n",
    "    random_state=seed,\n",
    "):\n",
    "    \n",
    "    if isinstance(cluster_std, float):\n",
    "        num_center = 1\n",
    "    elif isinstance(cluster_std, list):\n",
    "        num_center = len(cluster_std)\n",
    "    else:\n",
    "        # raise error\n",
    "        return\n",
    "\n",
    "    X, y = datasets.make_blobs(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        cluster_std=cluster_std,\n",
    "        random_state=random_state,\n",
    "        centers=num_center\n",
    "    )\n",
    "\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    unique_labels = np.unique(y)\n",
    "\n",
    "    if transforms is None:\n",
    "        transforms = {\n",
    "            label: rng.randn(n_features, n_features)*3.0\n",
    "            for label in unique_labels\n",
    "        }\n",
    "\n",
    "    X_transformed = np.zeros_like(X)\n",
    "    for label in unique_labels:\n",
    "        T = transforms[label]\n",
    "        X_transformed[y == label] = X[y == label] @ T.T\n",
    "\n",
    "    return X_transformed, y, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_nd_grid(grid_points_per_dim=10, n_dims=3, spacing=1.0, noise_std=0.1, seed=None):\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if isinstance(grid_points_per_dim, int):\n",
    "        grid_points_per_dim = [grid_points_per_dim] * n_dims\n",
    "    elif len(grid_points_per_dim) != n_dims:\n",
    "        raise ValueError(\"Length of grid_points_per_dim must match n_dims\")\n",
    "\n",
    "    # Create clean grid\n",
    "    grid_pts = [np.linspace(0, (n - 1) * spacing, n) for n in grid_points_per_dim]\n",
    "    mesh = np.meshgrid(*grid_pts, indexing='ij')\n",
    "    grid = np.stack(mesh, axis=-1).reshape(-1, n_dims)\n",
    "\n",
    "    # Add Gaussian noise\n",
    "    # TODO: VARY NOISE / HETEROSKEDASTIC\n",
    "    noise = rng.normal(scale=noise_std, size=grid.shape)\n",
    "    noisy_grid = grid + noise\n",
    "\n",
    "    return noisy_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_torus(n_samples=1000, R=2, r=1, noise=0.2, random_state=None, center=(0, 0, 0)):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    # Sample angles u, v uniformly\n",
    "    u = rng.uniform(0, 2 * np.pi, n_samples)\n",
    "    v = rng.uniform(0, 2 * np.pi, n_samples)\n",
    "    \n",
    "    # Parametric equations\n",
    "    x = (R + r * np.cos(v)) * np.cos(u)\n",
    "    y = (R + r * np.cos(v)) * np.sin(u)\n",
    "    z = r * np.sin(v)\n",
    "    \n",
    "    # Add Gaussian noise if requested\n",
    "    if noise > 0:\n",
    "        x += rng.normal(0, noise, n_samples)\n",
    "        y += rng.normal(0, noise, n_samples)\n",
    "        z += rng.normal(0, noise, n_samples)\n",
    "    \n",
    "    return np.stack([x, y, z], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115db9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_concentric_spheres(n_samples=1000,n_features=3,n_spheres=4,noise=0.2, center=(0, 0, 0), radii_arr=None):\n",
    "    \n",
    "    if radii_arr is None:\n",
    "        scale_factor = 50\n",
    "        radii_arr = np.linspace(1, n_spheres*scale_factor,n_spheres + 1)\n",
    "\n",
    "    n_samples_per_shell = int(n_samples / n_spheres)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    X_list = []\n",
    "\n",
    "    for i, r in enumerate(radii_arr):\n",
    "\n",
    "        # sample spherical coords\n",
    "        theta = rng.uniform(0, 2 * np.pi, n_samples_per_shell)\n",
    "        phi = np.arccos(rng.uniform(-1, 1, n_samples_per_shell))\n",
    "        \n",
    "        r_noisy = r + rng.normal(0, noise, n_samples_per_shell)\n",
    "        \n",
    "        r_noisy_x = r_noisy\n",
    "        r_noisy_y = r_noisy\n",
    "        r_noisy_z = r_noisy\n",
    "\n",
    "        # convert to feature vector\n",
    "        x = r_noisy_x * np.sin(phi) * np.cos(theta)\n",
    "        y = r_noisy_y * np.sin(phi) * np.sin(theta)\n",
    "        z = r_noisy_z * np.cos(phi)\n",
    "        \n",
    "        shell_points = np.stack([x, y, z], axis=1)\n",
    "        X_list.append(shell_points)\n",
    "    \n",
    "    X = np.vstack(X_list)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db403813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "\n",
    "def continuous_mi_matrix(X,dim=1):\n",
    "    n = X.shape[1]\n",
    "    mi_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        y = X[:, i]\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                mi_matrix[i, j] = 0  # MI with itself isn't informative\n",
    "            else:\n",
    "                mi_matrix[i, j] = mutual_info_regression(X[:, [j]], y, discrete_features=False)[0]\n",
    "    \n",
    "    return mi_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08454022",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEVER THE DATA IN SOME WAY -> EG DROPOUTS / REMOVE POINTS RANDOMLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b659684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_3d_points(X, theta1, theta2, theta3):\n",
    "\n",
    "    Rx = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(theta1), -np.sin(theta1)],\n",
    "        [0, np.sin(theta1),  np.cos(theta1)]\n",
    "    ])\n",
    "    \n",
    "    Ry = np.array([\n",
    "        [ np.cos(theta2), 0, np.sin(theta2)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(theta2), 0, np.cos(theta2)]\n",
    "    ])\n",
    "    \n",
    "    Rz = np.array([\n",
    "        [np.cos(theta3), -np.sin(theta3), 0],\n",
    "        [np.sin(theta3),  np.cos(theta3), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    R = Rz @ Ry @ Rx\n",
    "    \n",
    "    # Apply rotation\n",
    "    X_rotated = X @ R.T\n",
    "    return X_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD: paraboloids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccad6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gaus_homosk_blobs = datasets.make_blobs(n_samples=n_samples,n_features=n_features, random_state=seed)\n",
    "\n",
    "gaus_heterosk_blobs = datasets.make_blobs(\n",
    "    n_samples=n_samples,n_features=n_features, cluster_std=[2.0, 2.5, 0.5], random_state=seed\n",
    ")\n",
    "\n",
    "swissrolldata = datasets.make_swiss_roll(\n",
    "    n_samples=n_samples,random_state=seed,noise=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bb6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_gaus = datasets.make_blobs(n_samples=n_samples,n_features=n_features, random_state=seed,cluster_std=[1.0],centers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ellips_homosk_clusters = make_heteroskedastic_anisotropic_blobs_nd(cluster_std=[1.0,1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ellips_homosk_cluster_one = make_heteroskedastic_anisotropic_blobs_nd(cluster_std=[1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d67dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ellips_heterosk_clusters = make_heteroskedastic_anisotropic_blobs_nd(cluster_std=[1.0,0.3,2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471cd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_concentric_sph = noisy_concentric_spheres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62353be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_torus = noisy_torus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_noise_grid = generate_noisy_nd_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3be001",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_points, S_color = datasets.make_s_curve(n_samples, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cc5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lst = [\n",
    "    (gaus_homosk_blobs[0],{'name' : 'gaussian_homoskedastic',\n",
    "                           'class_label' : gaus_homosk_blobs[1]},),\n",
    "    (gaus_heterosk_blobs[0], {'name' : 'gaussian_heteroskedastic',\n",
    "                           'class_label' : gaus_heterosk_blobs[1]}),\n",
    "    (swissrolldata[0], {'name' : 'swissroll'}),\n",
    "    (ellips_homosk_clusters[0],{'name' : 'ellipsoid_homoskedastic',\n",
    "                                'class_label' : ellips_homosk_clusters[1]}),\n",
    "    (ellips_heterosk_clusters[0],{'name' : 'ellipsoid_heteroskedastic',\n",
    "                                'class_label' : ellips_heterosk_clusters[1]}),\n",
    "    (ellips_homosk_cluster_one[0],{'name' : 'aniso_gaus',}),\n",
    "    (iso_gaus[0],{'name' : 'iso_gaus',}),\n",
    "    (gauss_noise_grid,{'name' : 'noisy_grid',\n",
    "                        }),\n",
    "    (noisy_concentric_sph,{'name' : 'noisy_spheres',\n",
    "                        }),\n",
    "    (noisy_torus,{'name' : 'noisy_torus',\n",
    "                        }),\n",
    "    (S_points,{'name' : 's_curve',\n",
    "                        }),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656bd084",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i_dataset, (dataset_val, params_dict) in enumerate(dataset_lst):\n",
    "    X = dataset_val\n",
    "\n",
    "    y = None\n",
    "\n",
    "    # X = rotate_3d_points(X, np.pi/3, np.pi/4, 0)\n",
    "\n",
    "    if 'class_label' in params_dict.keys():\n",
    "        y = params_dict['class_label']\n",
    "\n",
    "\n",
    "    plot_3d_scatters(X,'')\n",
    "    plot_dist_distribution(X,point='global_median_centroid',dist_scale='none')\n",
    "    # fig.suptitle(params_dict['name'], fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6e529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b887f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lst = [\n",
    "    (gaus_homosk_blobs[0],{'name' : 'gaussian_homoskedastic',\n",
    "                           'class_label' : gaus_homosk_blobs[1]},),\n",
    "    (gaus_heterosk_blobs[0], {'name' : 'gaussian_heteroskedastic',\n",
    "                           'class_label' : gaus_heterosk_blobs[1]}),\n",
    "    (swissrolldata[0], {'name' : 'swissroll'}),\n",
    "    (ellips_homosk_clusters[0],{'name' : 'ellipsoid_homoskedastic',\n",
    "                                'class_label' : ellips_homosk_clusters[1]}),\n",
    "    (ellips_heterosk_clusters[0],{'name' : 'ellipsoid_heteroskedastic',\n",
    "                                'class_label' : ellips_heterosk_clusters[1]}),\n",
    "    (gauss_noise_grid,{'name' : 'noisy_grid',\n",
    "                        }),\n",
    "    (noisy_concentric_sph,{'name' : 'noisy_spheres',\n",
    "                        }),\n",
    "    (noisy_torus,{'name' : 'noisy_torus',\n",
    "                        }),\n",
    "    (S_points,{'name' : 's_curve',\n",
    "                        }),\n",
    "\n",
    "]\n",
    "\n",
    "for i_dataset, (dataset_val, params_dict) in enumerate(dataset_lst):\n",
    "    X = dataset_val\n",
    "\n",
    "    y = None\n",
    "\n",
    "    X = rotate_3d_points(X, np.pi/3, np.pi/4, 0)\n",
    "\n",
    "    if 'class_label' in params_dict.keys():\n",
    "        y = params_dict['class_label']\n",
    "\n",
    "    def scatter_helper(ax, xs, ys, zs=None, class_label = None):\n",
    "\n",
    "        if zs is not None:\n",
    "            if class_label is not None:\n",
    "                sc = ax.scatter(xs, ys, zs, c=class_label, cmap='tab10', s=10)\n",
    "            else:\n",
    "                sc = ax.scatter(xs, ys, zs, s=10)\n",
    "            return sc\n",
    "\n",
    "        else:\n",
    "            if class_label is not None:\n",
    "                sc = ax.scatter(xs, ys, c=class_label, cmap='tab10', s=10)\n",
    "            else:\n",
    "                sc = ax.scatter(xs, ys, s=10)\n",
    "            return sc\n",
    "        \n",
    "        return None\n",
    "\n",
    "    # normalize dataset\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # fig = plt.figure()    \n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 3), subplot_kw={})\n",
    "\n",
    "    axs[0] = fig.add_subplot(1, 4, 1, projection='3d')\n",
    "    xs,ys,zs = X[:, 0], X[:, 1], X[:, 2]\n",
    "    scatter_helper(axs[0],xs,ys,zs,y)\n",
    "    axs[0].set_title(params_dict['name'])\n",
    "\n",
    "    # 2D scatter plots\n",
    "    scatter_helper(axs[1],xs,ys,None,y)\n",
    "    axs[1].set_title('0 vs 1')\n",
    "\n",
    "    scatter_helper(axs[2],ys,zs,None,y)\n",
    "    axs[2].set_title('1 vs 2')\n",
    "\n",
    "    scatter_helper(axs[3],xs,zs,None,y)\n",
    "    axs[3].set_title('0 vs 2')\n",
    "        \n",
    "    # plt.xlim(-2.5, 2.5)\n",
    "    # plt.ylim(-2.5, 2.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig1, axs1 = plt.subplots(1, 5, figsize=(15, 3), subplot_kw={})\n",
    "\n",
    "    # fit a MCD robust estimator to data\n",
    "    cov_mat = MinCovDet().fit(X)\n",
    "    # cov_mat = np.cov(X, rowvar=False)\n",
    "    mask = np.triu(np.ones_like(cov_mat.covariance_, dtype=bool), k=1)  \n",
    "    # mask = np.ones()  \n",
    "    sns.heatmap(cov_mat.covariance_, mask=mask,ax=axs1[0], cbar=True, square=True,\n",
    "                annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    axs1[0].set_title('Covariance MCD')\n",
    "\n",
    "    # fit a MCD robust estimator to data\n",
    "    cov_mat = EmpiricalCovariance().fit(X)\n",
    "    # cov_mat = np.cov(X, rowvar=False)\n",
    "    mask = np.triu(np.ones_like(cov_mat.covariance_, dtype=bool), k=1)  \n",
    "    # mask = np.ones()  \n",
    "    sns.heatmap(cov_mat.covariance_, mask=mask,ax=axs1[1], cbar=True, square=True,\n",
    "                annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    axs1[1].set_title('Covariance Empirical')\n",
    "\n",
    "    mi_mtx = continuous_mi_matrix(X)\n",
    "    sns.heatmap(mi_mtx, ax=axs1[4], cbar=True, square=True,\n",
    "                annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    axs1[4].set_title('MI')\n",
    "\n",
    "    corr_coef = stats.spearmanr(X, axis=0).statistic\n",
    "    sns.heatmap(corr_coef, mask=mask,ax=axs1[2], cbar=True, square=True,\n",
    "                annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    axs1[2].set_title('SpearmanR')\n",
    "\n",
    "    # kernel_fn = 'sigmoid'\n",
    "    # corr_coef =  pairwise.pairwise_kernels(X.T, metric=kernel_fn)\n",
    "\n",
    "    kernel_fn = 'cosine'\n",
    "    corr_coef =  pairwise.cosine_similarity(X.T)\n",
    "\n",
    "    sns.heatmap(corr_coef, mask=mask,ax=axs1[3], cbar=True, square=True,\n",
    "                annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    axs1[3].set_title(f'Pairwise {kernel_fn}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6a076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3351cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[:,0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspoc)",
   "language": "python",
   "name": "pyspoc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
